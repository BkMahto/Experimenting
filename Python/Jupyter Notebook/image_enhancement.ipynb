{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "e1a1a1a1",
            "metadata": {},
            "source": [
                "# Image Enhancement & Background Removal\n",
                "This notebook provides tools to fix blurry/pixelated images and remove backgrounds cleanly.\n",
                "\n",
                "**Features:**\n",
                "- **Super Resolution (Upscaling):** Fixes blurry pixels and preserves transparency.\n",
                "- **Background Removal:** Extracts subjects without crashing in complex environments.\n",
                "- **Line-by-Line Documentation:** Beginner-friendly explanations for every step."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e2a2a2a2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Install specialized AI tools for image processing\n",
                "# Note: We use ipywidgets==7.7.1 to avoid a common rendering error in VS Code\n",
                "%pip install -q transformers torch Pillow ipywidgets==7.7.1 numpy torchvision"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e3a3a3a3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import the core engine 'torch' for AI math\n",
                "import torch\n",
                "# 'Image' tool for opening and seeing pictures\n",
                "from PIL import Image\n",
                "import io\n",
                "import numpy as np\n",
                "# 'AutoModelForImageSegmentation' is a specialized tool for background removal\n",
                "from transformers import AutoModelForImageSegmentation\n",
                "# 'pipeline' for specific AI tasks\n",
                "from transformers import pipeline\n",
                "# UI tools to create buttons and uploaders\n",
                "import ipywidgets as widgets\n",
                "from IPython.display import display\n",
                "from torchvision.transforms.functional import normalize\n",
                "\n",
                "# Detect if there is a fast Graphics Card (GPU) available\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Hardware detected: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e4a4a4a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Defining the Models ---\n",
                "BG_MODEL_ID = \"briaai/RMBG-1.4\"\n",
                "UPSCALER_MODEL_ID = \"caidas/swin2SR-classical-sr-x2-64\"\n",
                "\n",
                "# We load models only when needed to save your computer's memory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e5a5a5a5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Logic for Background Removal ---\n",
                "def remove_background(img):\n",
                "    print(\"Loading Background Removal Model...\")\n",
                "    model = AutoModelForImageSegmentation.from_pretrained(BG_MODEL_ID, trust_remote_code=True)\n",
                "    model.to(device)\n",
                "    model.eval()\n",
                "\n",
                "    # Standardize image for the AI (1024x1024)\n",
                "    original_size = img.size\n",
                "    input_images = img.convert(\"RGB\").resize((1024, 1024), Image.BILINEAR)\n",
                "    input_images = np.array(input_images) / 255.0\n",
                "    input_images = np.transpose(input_images, (2, 0, 1))\n",
                "    input_images = torch.tensor(input_images, dtype=torch.float32).unsqueeze(0).to(device)\n",
                "    input_images = normalize(input_images, [0.5, 0.5, 0.5], [1.0, 1.0, 1.0])\n",
                "\n",
                "    # Run AI inference\n",
                "    with torch.no_grad():\n",
                "        result = model(input_images)\n",
                "        # FIX: The model might return a list of tensors. We need the actual data tensor.\n",
                "        if isinstance(result, list):\n",
                "            preds = result[-1].sigmoid().cpu()\n",
                "        else:\n",
                "            preds = result.sigmoid().cpu()\n",
                "    \n",
                "    pred = preds[0].squeeze()\n",
                "    mask_image = Image.fromarray((pred.numpy() * 255).astype('uint8'), mode='L').resize(original_size, Image.BILINEAR)\n",
                "    \n",
                "    img_rgba = img.convert(\"RGBA\")\n",
                "    img_rgba.putalpha(mask_image)\n",
                "    return img_rgba\n",
                "\n",
                "# --- Logic for Upscaling with Transparency Preservation ---\n",
                "def upscale_image(img, keep_resolution=False):\n",
                "    print(\"Loading HD Enhancer (preserving transparency)...\")\n",
                "    orig_size = img.size\n",
                "    \n",
                "    # 1. Handle Transparency: Separate the \"Alpha\" channel\n",
                "    if img.mode == 'RGBA':\n",
                "        rgb_part = img.convert(\"RGB\")\n",
                "        alpha_part = img.getchannel('A')\n",
                "    else:\n",
                "        rgb_part = img.convert(\"RGB\")\n",
                "        alpha_part = None\n",
                "\n",
                "    # 2. Upscale the Colors with AI\n",
                "    upscaler = pipeline(\"image-to-image\", model=UPSCALER_MODEL_ID, device=0 if device == \"cuda\" else -1)\n",
                "    result = upscaler(rgb_part)\n",
                "    upscaled_rgb = result[0] if isinstance(result, list) else result\n",
                "    \n",
                "    # 3. Upscale the Transparency Mask (Lanczos resizing blends it perfectly)\n",
                "    target_size = upscaled_rgb.size\n",
                "    if alpha_part:\n",
                "        upscaled_alpha = alpha_part.resize(target_size, Image.LANCZOS)\n",
                "        final_image = upscaled_rgb.convert(\"RGBA\")\n",
                "        final_image.putalpha(upscaled_alpha)\n",
                "    else:\n",
                "        final_image = upscaled_rgb\n",
                "\n",
                "    # 4. Resolve Size: Shrink back if requested while keeping pixel quality\n",
                "    if keep_resolution:\n",
                "        print(f\"Finalizing at original size: {orig_size}\")\n",
                "        return final_image.resize(orig_size, Image.LANCZOS)\n",
                "    \n",
                "    return final_image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e6a6a6a6",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Interaction Dashboard ---\n",
                "uploader = widgets.FileUpload(accept='image/*', multiple=False, description=\"Upload\")\n",
                "task_selector = widgets.Dropdown(\n",
                "    options=[('Upscale (Fix Pixels)', 'upscale'), ('Remove Background', 'remove_bg')],\n",
                "    value='upscale', description='Task:',\n",
                ")\n",
                "resolution_check = widgets.Checkbox(value=False, description='Keep Original Resolution', indent=False)\n",
                "button = widgets.Button(description=\"Fix My Image\", button_style='success')\n",
                "output = widgets.Output()\n",
                "\n",
                "def on_click(b):\n",
                "    with output:\n",
                "        output.clear_output()\n",
                "        if not uploader.value: return print(\"No photo uploaded!\")\n",
                "        \n",
                "        val = list(uploader.value.values())[0] if isinstance(uploader.value, dict) else uploader.value[0]\n",
                "        input_image = Image.open(io.BytesIO(val['content']))\n",
                "        \n",
                "        print(f\"Action: {task_selector.label}...\")\n",
                "        try:\n",
                "            if task_selector.value == 'upscale':\n",
                "                final = upscale_image(input_image, keep_resolution=resolution_check.value)\n",
                "            else:\n",
                "                final = remove_background(input_image)\n",
                "            \n",
                "            print(\"Done! Opening result...\")\n",
                "            display(final)\n",
                "        except Exception as e:\n",
                "            print(f\"Error: {e}\")\n",
                "\n",
                "button.on_click(on_click)\n",
                "display(widgets.VBox([uploader, task_selector, resolution_check, button, output]))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}