{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "c1a1a1a1",
            "metadata": {},
            "source": [
                "# Image Compositing & Creative Merging\n",
                "This notebook allows you to blend two images together, place people in new environments, and perform \"Virtual Try-ons\".\n",
                "\n",
                "**Core Abilities:**\n",
                "- **Image Merging:** Combine a Person A with Place B.\n",
                "- **Identity Preservation:** Try to keep the same face while changing everything else.\n",
                "- **Virtual Try-on:** Swap clothing or textures using AI.\n",
                "- **Scene Context:** The AI matches lights and shadows automatically."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c2a2a2a2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Install powerful diffusion tools\n",
                "# %pip is the standard way to install packages inside a notebook\n",
                "%pip install -q diffusers transformers accelerate scipy ipywidgets Pillow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c3a3a3a3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import math and AI libraries\n",
                "import torch\n",
                "import io\n",
                "from PIL import Image, ImageOps\n",
                "# 'StableDiffusionInpaintPipeline' is the best tool for merging/changing parts of images\n",
                "from diffusers import StableDiffusionInpaintPipeline\n",
                "import ipywidgets as widgets\n",
                "from IPython.display import display\n",
                "\n",
                "# Check for GPU hardware for fast calculations\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Active hardware: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c4a4a4a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 2: Load the Creative AI Engine\n",
                "# 'runwayml/stable-diffusion-inpainting' is a version specifically trained to blend images\n",
                "model_id = \"runwayml/stable-diffusion-inpainting\"\n",
                "\n",
                "# Download the model from the internet\n",
                "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
                "    model_id, \n",
                "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
                ")\n",
                "\n",
                "# Move the model to your GPU or CPU\n",
                "pipe = pipe.to(device)\n",
                "\n",
                "print(\"Compositing Engine is ready!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c5a5a5a5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# This function handles the complex work of blending two images\n",
                "def merge_images(main_image, reference_mask, prompt, negative_prompt=\"\"):\n",
                "    # Standardize image sizes to 512x512 pixels\n",
                "    main_image = main_image.convert(\"RGB\").resize((512, 512))\n",
                "    # The 'mask' tells the AI which part of the photo to change vs keep\n",
                "    mask_image = reference_mask.convert(\"RGB\").resize((512, 512))\n",
                "    \n",
                "    print(f\"Blending images with prompt: {prompt[:30]}...\")\n",
                "    \n",
                "    # Use 'autocast' to make the math run efficiently\n",
                "    with torch.autocast(device):\n",
                "        # The pipeline takes the original photo, the mask (where to change), and the prompt\n",
                "        result = pipe(\n",
                "            prompt=prompt, \n",
                "            negative_prompt=negative_prompt, \n",
                "            image=main_image, \n",
                "            mask_image=mask_image\n",
                "        ).images[0]\n",
                "    \n",
                "    return result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c6a6a6a6",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Creative Compositing Dashboard ---\n",
                "\n",
                "print(\"HOW TO USE:\")\n",
                "print(\"1. Upload the Main Image (e.g., a person or a room).\")\n",
                "print(\"2. Upload a 'Mask' image (A black and white photo where WHITE is the area you want to change).\")\n",
                "print(\"3. Describe what should appear in the white area.\")\n",
                "\n",
                "# First uploader for the base photo\n",
                "main_uploader = widgets.FileUpload(description=\"Photo A (Base)\", multiple=False)\n",
                "# Second uploader for the mask (or reference)\n",
                "mask_uploader = widgets.FileUpload(description=\"Mask / Ref\", multiple=False)\n",
                "\n",
                "# Text boxes for what you want to see\n",
                "u_prompt = widgets.Textarea(\n",
                "    value='A man doing a dangerous stunt on top of a skyscraper, dramatic lighting, professional photography',\n",
                "    placeholder='What should happen in the masked area?',\n",
                "    description='Positive:',\n",
                "    layout=widgets.Layout(width='90%', height='80px')\n",
                ")\n",
                "\n",
                "u_negative = widgets.Textarea(\n",
                "    value='ugly, blurry, low quality, distorted hands, tattoos',\n",
                "    placeholder='What should the AI avoid?',\n",
                "    description='Negative:',\n",
                "    layout=widgets.Layout(width='90%', height='60px')\n",
                ")\n",
                "\n",
                "go_button = widgets.Button(description=\"Merge & Generate\", button_style='primary', layout=widgets.Layout(width='200px', height='40px'))\n",
                "c_output = widgets.Output()\n",
                "\n",
                "def on_go_clicked(b):\n",
                "    with c_output:\n",
                "        c_output.clear_output()\n",
                "        # Safety checks: ensure we have both photos\n",
                "        if not main_uploader.value or not mask_uploader.value:\n",
                "            print(\"Please upload BOTH the Main Photo and the Mask Photo (Ref).\")\n",
                "            return\n",
                "        \n",
                "        # Load Photo A\n",
                "        file_a = list(main_uploader.value.values())[0] if isinstance(main_uploader.value, dict) else main_uploader.value[0]\n",
                "        img_a = Image.open(io.BytesIO(file_a['content']))\n",
                "        \n",
                "        # Load Mask/Ref\n",
                "        file_b = list(mask_uploader.value.values())[0] if isinstance(mask_uploader.value, dict) else mask_uploader.value[0]\n",
                "        img_b = Image.open(io.BytesIO(file_b['content']))\n",
                "        \n",
                "        # Run the AI blending engine\n",
                "        final = merge_images(img_a, img_b, u_prompt.value, u_negative.value)\n",
                "        \n",
                "        # Show the result\n",
                "        print(\"Successfully Merged!\")\n",
                "        display(final)\n",
                "\n",
                "go_button.on_click(on_go_clicked)\n",
                "\n",
                "display(widgets.HBox([main_uploader, mask_uploader]), u_prompt, u_negative, go_button, c_output)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (Experimenting venv)",
            "language": "python",
            "name": "experimenting_venv"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}